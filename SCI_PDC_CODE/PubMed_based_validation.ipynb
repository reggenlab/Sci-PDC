{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install bio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import csv\n",
    "import numpy as np\n",
    "from Bio import Entrez\n",
    "from os import listdir \n",
    "import os\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 6000)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 800)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(func_word):     \n",
    "    result = re.sub('[^A-Za-z0-9]+', ' ', func_word) #remove underscores\n",
    "    result = re.sub(\" \\d+\", \"\", result) # remove numbers\n",
    "    result = result.lower() \n",
    "    result = re.sub(r'(?:^| )\\w(?:$| )', ' ', result).strip() #remove single letters\n",
    "    stopwords = {'cell','of','small','in','is','he', 'linked','to', 'an','from', 'by', 'on', 'the', 'or', 'like', 'layer','that','biology','peptide',\n",
    "                'ii', 'groups', 'into', 'type', 'reactome', 'kegg', 'pathway', 'and', 'processing', 'diabetes','term'\n",
    "                , 'signal', 'during','synthesis', 'secretion', 'cross', 'presentation', 'regulated', 'sodium', 'secreted','gap',\n",
    "                'factors', 'pid', 'channel', 'transport', 'activation', 'molecules', 'expression', 'pre','absence' ,'transmits', 'nucleus',\n",
    "                'downstream', 'golgi', 'mutants','human', 'by','hormone', 'pathways','biocarta','st','sa','sig','long','go','class','other','3','nuclear','metabolic',\n",
    "                'connection','chain','trans','aggregation','through','mature','signals','and10','phases','adhesion','exposed','aggregation','mediated','via','role','second','oxygen','biological'\n",
    "                ,'family','containing','receptors','disease','homo','highly','sapiens','diseases','associated','growth','elements','medial','antennae','cytoskeletal','rich' , 'repeat','double' , 'strand', 'break'}\n",
    "    result  = ' '.join(filter(lambda x: x.lower() not in stopwords,  result.split()))\n",
    "    if (len(result.split()) >= 2):\n",
    "        stopwords1 = {'binding', 'protein', 'gr','chaperones','targetting ','factor', 'remodelling','activity','attractive','activated', 'active','regulation', 'group', 'chemical', 'sensory', 'other', 'process', 'release',\n",
    "                    'species','receptor' ,'positive', 'derived','compound','permeable', 'cellular', 'particle', 'organism', 'involved', 'movement', 'termination','phosphate',\n",
    "                        'interaction', 'glycosylation','environment', 'pathway', 'signaling', 'coupled', 'mrna', 'response', 'negative','elevation','cleavage','xenobiotics','cytochrome',\n",
    "                        'modified', 'response', 'left', 'right', 'formation', 'nucleotide', 'gene', 'complex','migration','transporters','death','signalling',\n",
    "                        'dependent', 'maintenance', 'process', 'acid', 'cancer','n','o','one','homologous','non','metabolism','biosynthesis','transcription','methionine',\n",
    "                        'tumor','necrosis','elongation','pol','splicing','carbon','pool','series','glycosphingolipid','salt','interactions','transcriptional','white','phosphorylation',\n",
    "                        'oxidative','ligand','noncanonical','transcript','cytosolic','levels','cascade','events','genomic','global','basal','organization','junction','extension','association',\n",
    "                        'life','alpha','cycle','degradation','production','stabilization','proteins','amino','messengers','hydroxylation','hormones','membrane','glucose','transendothelial'}\n",
    "        result = ' '.join(filter(lambda x: x.lower() not in stopwords1,  result.split())) #second round\n",
    "        words = result.split()\n",
    "        result = \" \".join(sorted(set(words), key=words.index)) #remove duplicate words\n",
    "        result = re.sub(r'(?:^| )\\w(?:$| )', ' ', result).strip() #remove single letters\n",
    "    if (len(result.split()) >= 3):\n",
    "        stopwords3 = {'dna','mediated','TRANSPORT','replication','cytokine','rna','synapse ','digestion','interferon','cysteine','anemia','nephrin','stimulation','induced','induction','mitochondrial','stimulates','cardiomyopathy',\n",
    "        'differentiation','peptide','channels','subunit','chemokine','chemokines','activates','activated','elevation','phagocytosis','kinases','modification','post','platlet','origin','neurotransmitter',\n",
    "        'systemic','incision','oxidation','development','early','stimulation','apoptosis','glycoproteins','infection','heterotrimer','targets','infection','proteasome','respiratory','system'}\n",
    "        result = ' '.join(filter(lambda x: x.lower() not in stopwords3,  result.split()))\n",
    "    result = result.strip()\n",
    "    intact_func = func_word\n",
    "    result = ' OR '.join(result.split())\n",
    "    return result, intact_func\n",
    "\n",
    "#func_name to get the function name from main file & row to get the genes from data\n",
    "def make_terms(data, func_name, row):\n",
    "    func_word, intact_func = text_process(func_name) \n",
    "    gene_list = data.iloc[row, 1]\n",
    "    stopwords4 = {'type'} \n",
    "    gene_list = ' '.join(filter(lambda x: x.lower() not in stopwords4,  gene_list.split())) \n",
    "    words = [func_word, \"AND\", gene_list]\n",
    "    gene_func_terms =  ' '.join(words)\n",
    "    return gene_func_terms, func_word, intact_func\n",
    "\n",
    "\n",
    "def co_occurance(terms):\n",
    "    Entrez.email = \"smadhu270@gmail.com\"\n",
    "    search_results = Entrez.read(\n",
    "        Entrez.esearch(\n",
    "            db=\"pubmed\", term= terms, mindate=1990, maxdate=2022, datetype=\"pdat\", usehistory=\"y\", retmax='1000'\n",
    "        )\n",
    "    )\n",
    "    count = int(search_results[\"Count\"])\n",
    "    pmids = list(search_results[\"IdList\"])\n",
    "    print(terms)\n",
    "    print(\"counts:\", count)\n",
    "    print(\"pmids:\", len(pmids))\n",
    "    return count, pmids\n",
    "\n",
    "def mk_mats(data):\n",
    "    mat_names= [\"total_count\", \"func_name\", \"disease_name\"]\n",
    "    master_count = pd.DataFrame(index = data.iloc[:,0], columns = list(mat_names))\n",
    "    pmid_mat = pd.DataFrame(columns = data.iloc[:,0], index = list(range(0,2000)))\n",
    "    return master_count, pmid_mat\n",
    "def call_func(data):\n",
    "    master_count, pmid_mat = mk_mats(data)\n",
    "    for row in range(data.shape[0]):\n",
    "        print(\"row_number:\", row)\n",
    "        func_count = 0\n",
    "        func_array = []\n",
    "        pmid_array = []\n",
    "        func_name = data.iloc[row, 0]\n",
    "        gene_func_list, func_word, intact_func = make_terms(data, func_name, row)\n",
    "        print(gene_func_list)\n",
    "        if len(str(gene_func_list).split()) < 4:\n",
    "            continue\n",
    "        if len(gene_func_list) != 0:\n",
    "           counts, pmids = co_occurance(gene_func_list)\n",
    "           func_count = +counts\n",
    "           func_array.append(counts)\n",
    "           pmid_array.append(pmids)\n",
    "        if(sum(func_array) != 0):\n",
    "           master_count.loc[intact_func].loc[\"total_count\"] = func_count\n",
    "           master_count.loc[intact_func].loc[\"func_name\"] = func_name\n",
    "           master_count.loc[intact_func].loc[\"disease_name\"] = data.iloc[row, 1]\n",
    "           pmid_list = [item for sublist in pmid_array for item in sublist]\n",
    "           if(len(pmid_list) != 0):\n",
    "               pmid_list = pd.DataFrame(pmid_list); pmid_list.columns = [intact_func]\n",
    "               pmid_list.index = list(range(0, len(pmid_list)))\n",
    "               pmid_mat.loc[:, func_name] =  pmid_list\n",
    "    return master_count, pmid_mat\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "###############       EXECUTION        ##################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lis = pd.read_csv(\"all_pathway_list.txt\", sep = \"\\t\", header = None, low_memory=False)\n",
    "norm_pathway = pd.read_csv(\"bay_norm_path_nlp.txt\", sep = \"\\t\", header = None, low_memory=False)\n",
    "sequence=pd.DataFrame(norm_pathway.iloc[:,0])\n",
    "df1=path_lis\n",
    "\n",
    "# Default inner join\n",
    "df1 = pd.merge(df1, sequence, how=\"outer\",indicator=True)\n",
    "df4 = df1.loc[df1[\"_merge\"] == \"left_only\"].drop(\"_merge\", axis=1)\n",
    "original_pathway=df4\n",
    "\n",
    "random.seed(44)\n",
    "null_funcs = pd.DataFrame(random.sample(list(original_pathway.iloc[:,0]), norm_pathway.shape[0]))\n",
    "a=pd.DataFrame(['Diabetes mellitus']*10)\n",
    "null_data = pd.concat([null_funcs, a],axis=1)\n",
    "null_data.columns =['func_name', 'disease_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_freq, null_pmid = call_func(null_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_freq, pmid_mat = call_func(norm_pathway) #pmid_mat <- pubmed ids are saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_freq.to_csv(\"bay_norm_pathways_matches.csv\")\n",
    "pmid_mat.to_csv(\"bay_norm_pathways_match_pids.csv\")\n",
    "null_freq.to_csv(\"bay_norm_null_pathways_matches.csv\")\n",
    "null_pmid.to_csv(\"bay_norm_null_pathways_match_pids.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
